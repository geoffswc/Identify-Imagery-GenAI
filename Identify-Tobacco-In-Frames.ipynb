{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fda6e3b0-04d9-4fea-bc17-1621196f0006",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import requests\n",
    "import yaml\n",
    "import time\n",
    "import base64\n",
    "import mimetypes\n",
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from openai import AzureOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4c64b71-6b75-4601-8029-ca1ca221817b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load YAML file\n",
    "def load_config(filename):\n",
    "    with open(filename, 'r') as file:\n",
    "        config = yaml.safe_load(file) \n",
    "    return config\n",
    "\n",
    "config = load_config('config.yml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a28e27b-11ea-4ecc-8e74-2a19cc23bfb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "API_KEY = config['API_KEY']\n",
    "API_VERSION = config['API_VERSION']\n",
    "RESOURCE_ENDPOINT = config['RESOURCE_ENDPOINT']\n",
    "deployment = 'gpt-4o-2024-05-13'\n",
    "DEPLOYMENT_MODEL = config['DEPLOYMENT_MODEL']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc380a18-aac0-4185-afce-ee4327bcf5d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this method uses versa to extract an image from local storage\n",
    "\n",
    "def extractFromLocalImage(prompt, image_path):\n",
    "\n",
    "    with open(image_path, 'rb') as file:\n",
    "        image_bytes = file.read()\n",
    "\n",
    "    image_base64 = base64.b64encode(image_bytes).decode('utf-8')\n",
    "\n",
    "    client = AzureOpenAI(\n",
    "        api_key=API_KEY,\n",
    "        api_version=API_VERSION,\n",
    "        azure_endpoint=RESOURCE_ENDPOINT,\n",
    "    )\n",
    "\n",
    "    prompt += \" The filename is the end of the image path: \" + image_path\n",
    "\n",
    "    mime_type, _ = mimetypes.guess_type(image_path)\n",
    "\n",
    "    # Fallback in case MIME type couldn't be determined\n",
    "    if mime_type is None:\n",
    "        mime_type = \"application/octet-stream\" \n",
    "\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\"type\": \"text\", \"text\": prompt},\n",
    "                {\n",
    "                    \"type\": \"image_url\",\n",
    "                    \"image_url\": {\n",
    "                        #\"url\": f\"data:image/jpeg;base64,{image_base64}\"\n",
    "                        \"url\": f\"data:{mime_type};base64,{image_base64}\"\n",
    "                    },\n",
    "                },\n",
    "            ],\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=deployment,\n",
    "        messages=messages,\n",
    "        max_tokens=1000,\n",
    "    )\n",
    "\n",
    "    return response\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b41c7c9-bee1-4802-9cbb-96bede786e60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from local storage\n",
    "\n",
    "prompt = \"\"\"\n",
    "Describe smoking related elements of this image, if present. Format response sa tab delimited file, with fields: filename, smoking_present, short_description, extended_description. For fields with multiple entries, use commas to delimit. Use unkown if field value is\n",
    "undetermined. Do not include the field names, only the line of data.\n",
    "\"\"\"\n",
    "\n",
    "response = extractFromLocalImage(prompt, \"./extracted_frames/Camel%20filters__frame_0050__0-00-48.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82dec42b-19dd-447f-a1b2-ce980f6505d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e15aed98-4c4e-46c4-84ba-138d1b66d41c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "859ec55a-a9ec-4d3b-ab42-48b0c51e8279",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this next section reads the first 10 files from local storage\n",
    "\n",
    "# first, extract the local paths into a list \n",
    "#./Images/images/*.jpg\n",
    "\n",
    "jpg_files = glob.glob(\"./extracted_frames/*.jpg\")\n",
    "\n",
    "for i, img in enumerate(jpg_files):\n",
    "    print(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4365ea51-385e-422b-915f-c9708ba0b4cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# next, call versa to extract information from the text based on the prompt\n",
    "\n",
    "res = []\n",
    "for i, img in enumerate(jpg_files):\n",
    "    if i >= 3:\n",
    "        break\n",
    "    print(img)\n",
    "    response = extractFromLocalImage(prompt, img)\n",
    "    line = response.choices[0].message.content.split('\\t')\n",
    "    res.append(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "791afa90-4f9a-499f-b48e-1e62d7f5dcb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the results into a pandas dataframe\n",
    "data = res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf05fc40-8785-452d-ad52-0c53d6681f3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the headers\n",
    "headers = ['filename', 'smoking_present', 'short_description', 'extended_description']\n",
    "\n",
    "# Prepare the cleaned data\n",
    "cleaned_data = []\n",
    "errors = []\n",
    "\n",
    "\n",
    "#note - I print out the number of columns to see if we are producing a consistent dataframe, since Versa can produce one-off errors\n",
    "# with the prompt I used\n",
    "\n",
    "for row in data:\n",
    "    print(len(row))\n",
    "    if len(row) == len(headers):\n",
    "        cleaned_data.append(row)  # valid row\n",
    "    elif len(row) < len(headers):\n",
    "        errors.append(row)\n",
    "        # Pad missing columns with NaN\n",
    "        row += [np.nan] * (len(headers) - len(row))\n",
    "        cleaned_data.append(row)\n",
    "    elif len(row) > len(headers):\n",
    "        errors.append(row)\n",
    "        # Condense excess data points into a single string\n",
    "        condensed = ', '.join(row[len(headers):])  # Join extra values into a string\n",
    "        cleaned_data.append(row[:len(headers)] + [condensed])  # Add the condensed string\n",
    "\n",
    "# Create a DataFrame with the correct headers\n",
    "df = pd.DataFrame(cleaned_data, columns=headers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9a9e248-d2c8-4138-a08e-d33cf5d974f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46df63f7-51cd-4426-8a21-810245bfb140",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"smoking_detection_visual.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b14c3ff-ed9e-4c57-80a6-bf192cd8b632",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
